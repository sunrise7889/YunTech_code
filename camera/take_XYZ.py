# === Eye-to-Hand æ‰‹çœ¼æ ¡æ­£å®Œæ•´æ¨¡çµ„ ===
# åŠŸèƒ½ï¼šæ»‘é¼ é¸å››é»åš Homography â†’ è‡ªå‹•æŠ“æ£‹ç›¤è§’é» â†’ å„²å­˜ç›¸æ©Ÿè§’é» + æ©Ÿæ¢°æ‰‹è‡‚ XYZABCï¼ˆå…©æ®µå¼ï¼‰ â†’ è¨ˆç®—è½‰æ›çŸ©é™£

import cv2
import numpy as np
import pyrealsense2 as rs
from xarm.wrapper import XArmAPI
from scipy.spatial.transform import Rotation as R

# === åˆå§‹åŒ–æ‰‹è‡‚ ===
arm = XArmAPI('192.168.1.160')
arm.motion_enable(True)
arm.set_mode(0)
arm.set_state(0)
target_width, target_height = 600, 300

# === åˆå§‹åŒ– RealSense ===
pipeline = rs.pipeline()
config = rs.config()
config.enable_stream(rs.stream.color, 848, 480, rs.format.bgr8, 60)
config.enable_stream(rs.stream.depth, 848, 480, rs.format.z16, 60)
profile = pipeline.start(config)

# === æ»‘é¼ é»å››é»å»ºç«‹ Homography ===
clicked_points = []
H = None

def click_event(event, x, y, flags, param):
    if event == cv2.EVENT_LBUTTONDOWN and len(clicked_points) < 4:
        clicked_points.append([x, y])

print("[è«‹é»æ“Šç•«é¢å››å€‹è§’é»åšä¿¯è¦–è½‰æ›]")
while True:
    frames = pipeline.wait_for_frames()
    img = np.asanyarray(frames.get_color_frame().get_data())
    temp_img = img.copy()
    for pt in clicked_points:
        cv2.circle(temp_img, tuple(pt), 5, (0, 255, 0), -1)
    cv2.imshow("Select Points", temp_img)
    cv2.setMouseCallback("Select Points", click_event)
    if cv2.waitKey(1) == ord('q') or len(clicked_points) == 4:
        break
cv2.destroyWindow("Select Points")

dst = np.array([[0, 0], [target_width - 1, 0],
                       [target_width - 1, target_height - 1], [0, target_height - 1]], dtype=np.float32)
H = cv2.getPerspectiveTransform(np.array(clicked_points, dtype=np.float32), dst)
print("âœ… Homography å»ºç«‹å®Œæˆ")

# === æ£‹ç›¤æ ¼åƒæ•¸ ===
pattern_size = (6, 4)
square_size = 39
objp = np.zeros((np.prod(pattern_size), 3), np.float32)
objp[:, :2] = np.indices(pattern_size).T.reshape(-1, 2)
objp *= square_size

# === å„²å­˜ç”¨ ===
Rs_cam2target, Ts_cam2target = [], []
Rs_base2gripper, Ts_base2gripper = [], []

# === ç‹€æ…‹ï¼š0 ç­‰å¾…ç›¸æ©Ÿè§’é»ï¼Œ1 ç­‰å¾…æ‰‹è‡‚å°æº– ===
state = 0
print("[s] å„²å­˜è§’é»èˆ‡æ‰‹è‡‚å§¿æ…‹é…å°ï¼ˆå…©æ®µå¼ï¼‰ï¼Œ[q] é›¢é–‹")
while True:
    frames = pipeline.wait_for_frames()
    color_frame = frames.get_color_frame()
    img = np.asanyarray(color_frame.get_data())
    warped = cv2.warpPerspective(img, H, (600, 300))
    gray = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)

    ret, corners = cv2.findChessboardCorners(gray, pattern_size, None)
    if ret:
        corners_sub = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1), 
            (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))
        cv2.drawChessboardCorners(warped, pattern_size, corners_sub, ret)
        # æ¨™è¨˜è§’é» 0
        cv2.circle(warped, tuple(corners_sub[0][0].astype(int)), 8, (0, 0, 255), -1)
        cv2.putText(warped, "P0", tuple(corners_sub[0][0].astype(int) + np.array([5, -5])),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
        cv2.imshow("Chessboard", warped)

        key = cv2.waitKey(1)
        if key == ord('s'):
            if state == 0:
                retval, rvec, tvec = cv2.solvePnP(objp, corners_sub, np.eye(3), None)
                R_cam, _ = cv2.Rodrigues(rvec)
                Rs_cam2target.append(R_cam)
                Ts_cam2target.append(tvec)
                print("ğŸ“Œ å·²å„²å­˜ç›¸æ©Ÿè§’é»è³‡è¨Šï¼Œè«‹ç§»å‹•æ‰‹è‡‚æœ«ç«¯å°æº–ç´…é»å¾Œå†æŒ‰ s")
                state = 1
            elif state == 1:
                pos = arm.get_position(is_radian=False)
                if not isinstance(pos, list) or len(pos) < 6:
                    print("âŒ ç„¡æ³•å–å¾—æœ‰æ•ˆæ‰‹è‡‚ä½ç½®ï¼Œpos =", pos)
                    continue
                xyz = np.array(pos[:3])
                rpy = R.from_euler('xyz', pos[3:6], degrees=True)
                Rs_base2gripper.append(rpy.as_matrix())
                Ts_base2gripper.append(xyz.reshape(3,1))
                print(f"âœ… å·²å„²å­˜ç¬¬ {len(Rs_cam2target)} ç­†å°æ‡‰é»ï¼ˆç›¸æ©Ÿ + æ‰‹è‡‚ï¼‰")
                state = 0
        elif key == ord('q'):
            break
    else:
        cv2.imshow("Chessboard", warped)
        if cv2.waitKey(1) == ord('q'):
            break

pipeline.stop()
cv2.destroyAllWindows()

# === åŸ·è¡Œæ ¡æ­£ ===
R_cam2arm, t_cam2arm = cv2.calibrateHandEye(
    Rs_base2gripper, Ts_base2gripper,
    Rs_cam2target, Ts_cam2target,
    method=cv2.CALIB_HAND_EYE_TSAI
)
T = np.eye(4)
T[:3, :3] = R_cam2arm
T[:3, 3] = t_cam2arm.flatten()
np.save("cam2arm_matrix.npy", T)
print("\nâœ… æ ¡æ­£å®Œæˆï¼Œè½‰æ›çŸ©é™£ cam2arm_matrix.npy å·²å„²å­˜ï¼š")
print(T)
